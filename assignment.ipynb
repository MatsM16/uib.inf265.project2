{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCH_COUNT = 1\n",
    "\n",
    "torch.manual_seed(420)\n",
    "\n",
    "# One for each digit\n",
    "CLASS_COUNT = 10\n",
    "# confidence, x, y, width, height, class probabilities\n",
    "PARAMS_PER_PRED = 5 + CLASS_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name:str):\n",
    "    train = torch.load(f'data/{name}_train.pt')\n",
    "    val = torch.load(f'data/{name}_val.pt')\n",
    "    test = torch.load(f'data/{name}_test.pt')\n",
    "\n",
    "    print(f\"Dataset '{name}'\")\n",
    "    print(f\"Training size:   {len(train)}\")\n",
    "    print(f\"Validation size: {len(val)}\")\n",
    "    print(f\"Test size:       {len(test)}\")\n",
    "\n",
    "    train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "def split_label(label_tensor):\n",
    "    confidence = label_tensor[:, 0:1]\n",
    "    box = label_tensor[:, 1:5]\n",
    "    classes = label_tensor[:, 5:]\n",
    "\n",
    "    return confidence, box, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object localization\n",
    "Localize and classify images of digits.\n",
    "- Image dimensions are `height=48`, `wight=60` and `channels=1`\n",
    "- Each image contains exactly **one** digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load localization datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'localization'\n",
      "Training size:   59400\n",
      "Validation size: 6600\n",
      "Test size:       11000\n"
     ]
    }
   ],
   "source": [
    "loc_train, loc_val, loc_test = load_dataset('localization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnV1(nn.Module):\n",
    "    \"\"\"\n",
    "    Expected input image to be 48x60x3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CnnV1, self).__init__()\n",
    "        \n",
    "        # Data = 48x60x3\n",
    "\n",
    "        self.l1_conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l2_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Data = 24x30x10\n",
    "\n",
    "        self.l3_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l4_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Data = 12x15x10\n",
    "\n",
    "        self.l5_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l6_pool = nn.MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=0)\n",
    "\n",
    "        # Data = 6x5x10\n",
    "\n",
    "        self.l7_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Data = 6x5x10\n",
    "\n",
    "        self.l8_fc = nn.Linear(in_features=6*5*10, out_features=100)\n",
    "        self.l9_fc = nn.Linear(in_features=100, out_features=PARAMS_PER_PRED)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x = torch.relu(self.l1_conv(x))\n",
    "        x = self.l2_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l3_conv(x))\n",
    "        x = self.l4_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l5_conv(x))\n",
    "        x = self.l6_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l7_conv(x))\n",
    "\n",
    "        x = x.view(-1, 6*5*10)\n",
    "\n",
    "        x = torch.relu(self.l8_fc(x))\n",
    "\n",
    "        x = torch.relu(self.l9_fc(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_confidence = nn.BCEWithLogitsLoss()\n",
    "loss_fn_class = nn.CrossEntropyLoss()\n",
    "loss_fn_box = nn.MSELoss()\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    # Extract true values\n",
    "    y_true_confidence, y_true_box, y_true_classes = split_label(y_true)\n",
    "\n",
    "    # Convert class labels to one-hot\n",
    "    y_true_classes = torch.nn.functional.one_hot(y_true_classes.long(), num_classes=CLASS_COUNT).float()\n",
    "    \n",
    "    # Extract predicted values\n",
    "    y_pred_confidence, y_pred_box, y_pred_classes = split_label(y_pred)\n",
    "\n",
    "    # Calculate confidence loss\n",
    "    loss = loss_fn_confidence(y_pred_confidence, y_true_confidence)\n",
    "\n",
    "    # Aggregate loss for each label in the batch\n",
    "    for i in range(y_true.shape[0]):\n",
    "\n",
    "        contains_object = y_true_confidence[i].item() != 0\n",
    "\n",
    "        # Only add class and box loss if the label contains an object\n",
    "\n",
    "        if contains_object:\n",
    "            loss_class = loss_fn_class(y_pred_classes[i,:], y_true_classes[i,0])\n",
    "            loss_box = loss_fn_box(y_pred_box[i,:], y_true_box[i,:])\n",
    "            loss = loss + loss_class + loss_box\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(EPOCH_COUNT):\n",
    "        for X, Y_true in loc_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            Y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(Y_true, Y_pred)\n",
    "\n",
    "            loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[274], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cnnv1_1 \u001b[38;5;241m=\u001b[39m CnnV1()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnnv1_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[273], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH_COUNT):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, Y_true \u001b[38;5;129;01min\u001b[39;00m loc_train:\n\u001b[1;32m---> 37\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m         Y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     41\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_fn(Y_true, Y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Mats\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mats\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\decorators.py:46\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     44\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mats\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:437\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mats\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:826\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    824\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mats\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnnv1_1 = CnnV1()\n",
    "\n",
    "train(cnnv1_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

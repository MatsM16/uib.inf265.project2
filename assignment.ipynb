{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCH_COUNT = 5\n",
    "\n",
    "torch.manual_seed(420)\n",
    "\n",
    "CLASS_COUNT = 10 # One for each digit\n",
    "PARAMS_PER_PRED = 5 + CLASS_COUNT # confidence, x, y, width, height, class probabilities\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "ACCURACY_WEIGHT = 0.5\n",
    "IOU_WEIGHT = 1 - ACCURACY_WEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name:str):\n",
    "    train = torch.load(f'data/{name}_train.pt')\n",
    "    val = torch.load(f'data/{name}_val.pt')\n",
    "    test = torch.load(f'data/{name}_test.pt')\n",
    "\n",
    "    print(f\"Dataset '{name}'\")\n",
    "    print(f\"Training size:   {len(train)}\")\n",
    "    print(f\"Validation size: {len(val)}\")\n",
    "    print(f\"Test size:       {len(test)}\")\n",
    "\n",
    "    train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "def split_label(label_tensor):\n",
    "    confidence = label_tensor[:, 0:1]\n",
    "    box = label_tensor[:, 1:5]\n",
    "    classes = label_tensor[:, 5:]\n",
    "\n",
    "    return confidence, box, classes\n",
    "\n",
    "def get_iou(box1:[float], box2:[float]):\n",
    "    X, Y, W, H = 0, 1, 2, 3\n",
    "\n",
    "    # Calculate area of intersection rectangle\n",
    "    intersection_width = min(box1[X] + box1[W], box2[X] + box2[W]) - max(box1[X], box2[X])\n",
    "    intersection_height = min(box1[Y] + box1[H], box2[Y] + box2[H]) - max(box1[Y], box2[Y])\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "\n",
    "    # Calculate areas of both boxes\n",
    "    box1_area = box1[W] * box1[H]\n",
    "    box2_area = box2[W] * box2[H]\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    if union_area < 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate IoU\n",
    "    return intersection_area / union_area\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object localization\n",
    "Localize and classify images of digits.\n",
    "- Image dimensions are `height=48`, `wight=60` and `channels=1`\n",
    "- Each image contains exactly **one** digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load localization datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'localization'\n",
      "Training size:   59400\n",
      "Validation size: 6600\n",
      "Test size:       11000\n"
     ]
    }
   ],
   "source": [
    "loc_train, loc_val, loc_test = load_dataset('localization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnV1(nn.Module):\n",
    "    \"\"\"\n",
    "    Expected input image to be 48x60x3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CnnV1, self).__init__()\n",
    "        \n",
    "        # Data = 48x60x3\n",
    "\n",
    "        self.l1_conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l2_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Data = 24x30x10\n",
    "\n",
    "        self.l3_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l4_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Data = 12x15x10\n",
    "\n",
    "        self.l5_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.l6_pool = nn.MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=0)\n",
    "\n",
    "        # Data = 6x5x10\n",
    "\n",
    "        self.l7_conv = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Data = 6x5x10\n",
    "\n",
    "        self.l8_fc = nn.Linear(in_features=6*5*10, out_features=100)\n",
    "        self.l9_fc = nn.Linear(in_features=100, out_features=PARAMS_PER_PRED)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        x = torch.relu(self.l1_conv(x))\n",
    "        x = self.l2_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l3_conv(x))\n",
    "        x = self.l4_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l5_conv(x))\n",
    "        x = self.l6_pool(x)\n",
    "\n",
    "        x = torch.relu(self.l7_conv(x))\n",
    "\n",
    "        x = x.view(-1, 6*5*10)\n",
    "\n",
    "        x = torch.relu(self.l8_fc(x))\n",
    "\n",
    "        x = torch.relu(self.l9_fc(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_confidence = nn.BCEWithLogitsLoss()\n",
    "loss_fn_class = nn.CrossEntropyLoss()\n",
    "loss_fn_box = nn.MSELoss()\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    # Extract true values\n",
    "    y_true_confidence, y_true_box, y_true_classes = split_label(y_true)\n",
    "\n",
    "    # Convert class labels to one-hot\n",
    "    y_true_classes = torch.nn.functional.one_hot(y_true_classes.long(), num_classes=CLASS_COUNT).float()\n",
    "    \n",
    "    # Extract predicted values\n",
    "    y_pred_confidence, y_pred_box, y_pred_classes = split_label(y_pred)\n",
    "\n",
    "    # Calculate confidence loss\n",
    "    loss = loss_fn_confidence(y_pred_confidence, y_true_confidence)\n",
    "\n",
    "    # Aggregate loss for each label in the batch\n",
    "    for i in range(y_true.shape[0]):\n",
    "\n",
    "        contains_object = y_true_confidence[i].item() >= CONFIDENCE_THRESHOLD\n",
    "\n",
    "        # Only add class and box loss if the label contains an object\n",
    "\n",
    "        if contains_object:\n",
    "            loss_class = loss_fn_class(y_pred_classes[i,:], y_true_classes[i,0])\n",
    "            loss_box = loss_fn_box(y_pred_box[i,:], y_true_box[i,:])\n",
    "            loss = loss + loss_class + loss_box\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(EPOCH_COUNT):\n",
    "        aggregate_loss = 0.0\n",
    "\n",
    "        for X, Y_true in loc_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            Y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(Y_true, Y_pred)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            aggregate_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCH_COUNT} - Loss: {aggregate_loss}\")\n",
    "\n",
    "def validate(model, dataset):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "\n",
    "        aggregate_iou = 0.0\n",
    "        aggregate_iou_count = 0\n",
    "\n",
    "        for x, y_true in dataset:\n",
    "\n",
    "            y_true_confidence = y_true[0:1].item()\n",
    "            y_true_box = y_true[1:5].tolist()\n",
    "            y_true_class = y_true[5:].long().item()\n",
    "\n",
    "            y_pred = model(x)\n",
    "            y_pred_confidence = torch.sigmoid(y_pred[0, 0:1]).item()\n",
    "            y_pred_box = y_pred[0, 1:5].tolist()\n",
    "            y_pred_class = y_pred[0, 5:].argmax(dim=-1).tolist()\n",
    "\n",
    "            total_count += 1\n",
    "\n",
    "            if y_true_confidence < CONFIDENCE_THRESHOLD:\n",
    "                if y_pred_confidence < CONFIDENCE_THRESHOLD:\n",
    "                    correct_count += 1\n",
    "                continue\n",
    "\n",
    "            if y_pred_confidence < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            if y_true_class == y_pred_class:\n",
    "                correct_count += 1\n",
    "\n",
    "            aggregate_iou_count += 1\n",
    "            aggregate_iou += get_iou(y_true_box, y_pred_box)\n",
    "\n",
    "        accuracy = correct_count / total_count\n",
    "        iou = aggregate_iou / aggregate_iou_count\n",
    "        performance = (accuracy * ACCURACY_WEIGHT) + (iou * IOU_WEIGHT)\n",
    "\n",
    "        print(f\"Validation - Accuracy: {accuracy}, IoU: {iou}, Performance: {performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 133675.81755542755\n",
      "Epoch 2/5 - Loss: 133671.76979637146\n",
      "Epoch 3/5 - Loss: 133671.40523147583\n",
      "Epoch 4/5 - Loss: 133407.37353515625\n",
      "Epoch 5/5 - Loss: 132834.73357963562\n",
      "Validation - Accuracy: 0.08757575757575757, IoU: 1.2817654849965137, Performance: 0.6846706212861356\n"
     ]
    }
   ],
   "source": [
    "cnnv1_1 = CnnV1()\n",
    "\n",
    "train(cnnv1_1)\n",
    "validate(cnnv1_1, loc_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

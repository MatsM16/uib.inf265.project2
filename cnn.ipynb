{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 265\n",
    "EPOCH_COUNT = 10\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object localization\n",
    "Classify and locate a single digit within the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "\n",
    "        # Input = (1, 48, 60)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Input = (32, 24, 30)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Input = (64, 12, 15)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3))\n",
    "        )\n",
    "\n",
    "        # Input = (128, 6, 5)\n",
    "        self.cnn_size = 128 * 6 * 5\n",
    "\n",
    "        self.confidence = nn.Sequential(\n",
    "            nn.Linear(self.cnn_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.cnn_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.bbox = nn.Sequential(\n",
    "            nn.Linear(self.cnn_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(-1, self.cnn_size)\n",
    "\n",
    "        return self.confidence(out), self.classifier(out), self.bbox(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_localizer(model:nn.Module, optimizer, name:str):\n",
    "\n",
    "    print(f\"Training: {name}\")\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(EPOCH_COUNT):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_size = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Split the label into the different parts\n",
    "            true_confidence = labels[:, 0]\n",
    "            true_class = F.one_hot(labels[:, -1].long(), num_classes=10).float()\n",
    "            true_bbox = labels[:, 1:5]\n",
    "\n",
    "            # Create mask for images with objects\n",
    "            has_object_mask = true_confidence > 0.5\n",
    "            \n",
    "            # Zero model gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Make predictions\n",
    "            pred_confidence, pred_class, pred_bbox = model(images)\n",
    "            pred_confidence = pred_confidence.squeeze()  # Fix the shape\n",
    "            \n",
    "            # We calculate confidence loss for all images\n",
    "            loss_confidence = F.binary_cross_entropy(pred_confidence, true_confidence)\n",
    "\n",
    "            # We use the mask to only calculate bbox and class loss for images with objects\n",
    "            loss_bbox = F.mse_loss(pred_bbox[has_object_mask], true_bbox[has_object_mask])\n",
    "            loss_class = F.cross_entropy(pred_class[has_object_mask], true_class[has_object_mask])\n",
    "\n",
    "            # Calculate total loss and gradients\n",
    "            loss = (loss_confidence + loss_bbox + loss_class)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update model weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Keep track of loss\n",
    "            total_size += images.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        epoch_loss = total_loss / total_size\n",
    "        losses.append(epoch_loss)\n",
    "        torch.save(model.state_dict(), f'models/train/{name}_e{epoch}.pt')\n",
    "        print(f'Epoch {epoch + 1}/{EPOCH_COUNT}, \\tLoss: {epoch_loss}')\n",
    "\n",
    "    torch.save(model.state_dict(), f'models/{name}.pt')\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"Loss for {name}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(f\"assets/loss_{name}.png\")\n",
    "\n",
    "def train_or_load_localizer(model:nn.Module, optimizer, name:str):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(f'models/{name}.pt'))\n",
    "        model.eval()\n",
    "        print(f\"Loaded: {name}\")\n",
    "    except FileNotFoundError:\n",
    "        train_localizer(model, optimizer, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = LocalizationNetwork()\n",
    "v1_optimizer = torch.optim.Adam(v1.parameters(), lr=0.0001)\n",
    "train_or_load_localizer(v1, v1_optimizer, \"v1_adam_lr0.0001\")\n",
    "\n",
    "v2 = LocalizationNetwork()\n",
    "v2_optimizer = torch.optim.Adam(v2.parameters(), lr=0.001)\n",
    "train_or_load_localizer(v2, v2_optimizer, \"v2_adam_lr0.001\")\n",
    "\n",
    "v3 = LocalizationNetwork()\n",
    "v3_optimizer = torch.optim.Adam(v3.parameters(), lr=0.001, weight_decay=0.001)\n",
    "train_or_load_localizer(v3, v3_optimizer, \"v3_adam_lr0.001_wd0.001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
